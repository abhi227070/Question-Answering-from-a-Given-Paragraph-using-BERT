# Question-Answering with BERT

## Table of Contents
1. [Overview](#overview)
2. [Objective](#objective)
3. [Usage](#usage)
4. [Screenshots](#screenshots)
5. [Acknowledgements](#acknowledgements)
6. [License](#license)

## Overview

This project focuses on building a Question-Answering (QA) system using BERT (Bidirectional Encoder Representations from Transformers), a language model developed by Google. The system is designed to understand a given text passage and provide accurate answers to questions based on the information in the passage.

## Objective

The main objective of this project is to fine-tune the BERT model on a specific text passage so that it can effectively answer questions related to that passage. By training BERT on relevant data, we aim to improve its ability to comprehend and respond to queries, thereby creating a useful QA system.

## Usage

To use this QA system:
1. Download the repository.
2. Upload the Jupyter Notebook file to Google Colab.
3. Run each cell sequentially to fine-tune the BERT model and load the necessary dependencies.
4. Input a paragraph and questions related to that paragraph.
5. The system will provide answers based on the information learned during training.

## Screenshots

![Screenshot 1](screenshots/screenshot1.png)
![Screenshot 1](screenshots/screenshot2.png)


## Acknowledgements

This project utilizes the BERT model developed by Google for question-answering tasks.

## License

This project is licensed under the terms of the MIT license. See the [LICENSE](LICENSE) file for details.
