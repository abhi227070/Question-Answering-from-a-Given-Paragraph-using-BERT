{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "TWAAAw9Axv-t"
      },
      "outputs": [],
      "source": [
        "# Importing all the required dependencies\n",
        "import transformers\n",
        "from transformers import TFBertForQuestionAnswering\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the given context\n",
        "\n",
        "context = \"\"\"The Maldives government on Sunday suspended three of its ministers over derogatory remarks made against India and Prime Minister Narendra Modi after he posted about his trip to Lakshadweep on social media platform X.\n",
        "According to several media reports, ministers Mariyam Shiuna, Malsha Shareef, and Mahzoom Majid have been suspended for triggering a massive row which has resulted in 'Boycott Maldives' trending on social media platforms.\n",
        "\"The foreign ministry has issued a statement on the social media posts that are insulting to neighbouring India ... Those who made such posts on social media while in government positions have now been suspended from their jobs,\" the Maldives government said in a statement.\n",
        "Shiuna's tweet, which has now been deleted, described PM Modi in a derogatory way using emojis. Malsha also shared PM Modi's video on X using derisive emojis.\n",
        "Maldivian politician Zahid Rameez, a council member of the Progressive Party of Maldives (PPM), which is part of the ruling collation, mocked the PM's visit and said India would never be able to compete with Maldives in regards to tourism.\"\"\"\n",
        "\n",
        "\n",
        "# These are some questions which we are going to ask to BERT model\n",
        "question = [\n",
        "    \"Who is the Prime Minister of India?\",\n",
        "    \"How many politicians are suspanded for over derogatory remarks made against India?\",\n",
        "]"
      ],
      "metadata": {
        "id": "5B1Qk44_yoit"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the tokenizer of the BERT model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"deepset/bert-base-cased-squad2\")\n",
        "\n",
        "# Importing the BERT model\n",
        "model = TFBertForQuestionAnswering.from_pretrained(\"deepset/bert-base-cased-squad2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bDUJOU-Tn0M",
        "outputId": "f8f1b2c8-d4e6-4577-e572-b5c5922c3706"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
            "\n",
            "All the weights of TFBertForQuestionAnswering were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing the first question and print the encoded output\n",
        "tokenizer.encode(question[0],truncation = True, padding = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCchFBmoT2y_",
        "outputId": "5d19bf8a-e58d-4555-b763-4b6b8b4b14b2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 2627, 1110, 1103, 3460, 2110, 1104, 1726, 136, 102]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the BERT \"Question - Answering\" pipeline\n",
        "nlp = pipeline('question-answering',model = model,tokenizer = tokenizer)"
      ],
      "metadata": {
        "id": "fhiQNX5HWKsJ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a chatbot function for question answering\n",
        "def chatbot(question,context):\n",
        "\n",
        "  output = nlp({\n",
        "      \"question\": question,\n",
        "      \"context\": context\n",
        "  })\n",
        "  return output['answer']"
      ],
      "metadata": {
        "id": "TaJfBj_GXYMy"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asking the first question to the chatbot\n",
        "\n",
        "print(\"Question: \",question[0])\n",
        "print(\"Answer: \",chatbot(question[0],context))"
      ],
      "metadata": {
        "id": "4-RwF9tGX8v5",
        "outputId": "89ac1607-78c1-4c85-b69d-073f54da6977",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:  Who is the Prime Minister of India?\n",
            "Answer:  Narendra Modi\n"
          ]
        }
      ]
    }
  ]
}